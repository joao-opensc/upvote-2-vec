--- Starting Data Preparation ---
Filtered to 669,341 samples.
âœ… Base features engineered.
ðŸš€ Performing data augmentation...
âœ… Augmentation complete. Total samples: 689,920
Loading GloVe word vectors...
âœ… GloVe embeddings loaded: 400,000 words, 200 dim.
--- Data Preparation Finished ---
Split sizes: Train=413,952, Val=103,488, Test=172,480

--- Starting Training ---
Epoch 1/100 | Train Loss: 1.9270 | Val Loss: 1.5993 | Val RÂ²: -0.1525
  ðŸŽ¯ New best model saved with RÂ²: -0.1525
Epoch 2/100 | Train Loss: 1.5022 | Val Loss: 1.7856 | Val RÂ²: -0.1869
Epoch 3/100 | Train Loss: 1.4632 | Val Loss: 1.6476 | Val RÂ²: -0.1693
Epoch 4/100 | Train Loss: 1.4399 | Val Loss: 1.4900 | Val RÂ²: -0.1272
  ðŸŽ¯ New best model saved with RÂ²: -0.1272
Epoch 5/100 | Train Loss: 1.4330 | Val Loss: 1.4552 | Val RÂ²: -0.1088
  ðŸŽ¯ New best model saved with RÂ²: -0.1088
Epoch 6/100 | Train Loss: 1.4281 | Val Loss: 1.4384 | Val RÂ²: -0.0913
  ðŸŽ¯ New best model saved with RÂ²: -0.0913
Epoch 7/100 | Train Loss: 1.4238 | Val Loss: 1.4437 | Val RÂ²: -0.0985
Epoch 8/100 | Train Loss: 1.4209 | Val Loss: 1.4360 | Val RÂ²: -0.0819
  ðŸŽ¯ New best model saved with RÂ²: -0.0819
Epoch 9/100 | Train Loss: 1.4196 | Val Loss: 1.4454 | Val RÂ²: -0.1029
Epoch 10/100 | Train Loss: 1.4181 | Val Loss: 1.4347 | Val RÂ²: -0.0703
  ðŸŽ¯ New best model saved with RÂ²: -0.0703
Epoch 11/100 | Train Loss: 1.4168 | Val Loss: 1.4414 | Val RÂ²: -0.0959
Epoch 12/100 | Train Loss: 1.4330 | Val Loss: 1.4309 | Val RÂ²: -0.0698
  ðŸŽ¯ New best model saved with RÂ²: -0.0698
Epoch 13/100 | Train Loss: 1.4135 | Val Loss: 1.4309 | Val RÂ²: -0.0667
  ðŸŽ¯ New best model saved with RÂ²: -0.0667
Epoch 14/100 | Train Loss: 1.4127 | Val Loss: 1.4351 | Val RÂ²: -0.0477
  ðŸŽ¯ New best model saved with RÂ²: -0.0477
Epoch 15/100 | Train Loss: 1.4173 | Val Loss: 1.4417 | Val RÂ²: -0.0790
Epoch 16/100 | Train Loss: 1.4151 | Val Loss: 1.4324 | Val RÂ²: -0.0467
  ðŸŽ¯ New best model saved with RÂ²: -0.0467
Epoch 17/100 | Train Loss: 1.4114 | Val Loss: 1.4358 | Val RÂ²: -0.0419
  ðŸŽ¯ New best model saved with RÂ²: -0.0419
Epoch 18/100 | Train Loss: 1.4075 | Val Loss: 1.4370 | Val RÂ²: -0.1315
Epoch 19/100 | Train Loss: 1.3949 | Val Loss: 1.4250 | Val RÂ²: -0.0572
Epoch 20/100 | Train Loss: 1.3908 | Val Loss: 1.4231 | Val RÂ²: -0.0606
Epoch 21/100 | Train Loss: 1.3878 | Val Loss: 1.4241 | Val RÂ²: -0.0677
Epoch 22/100 | Train Loss: 1.3853 | Val Loss: 1.4253 | Val RÂ²: -0.0513
Epoch 23/100 | Train Loss: 1.3846 | Val Loss: 1.4246 | Val RÂ²: -0.0474
Epoch 24/100 | Train Loss: 1.3832 | Val Loss: 1.4236 | Val RÂ²: -0.0449
Epoch 25/100 | Train Loss: 1.3814 | Val Loss: 1.4243 | Val RÂ²: -0.0523
Epoch 26/100 | Train Loss: 1.3791 | Val Loss: 1.4269 | Val RÂ²: -0.0654
Epoch 27/100 | Train Loss: 1.3710 | Val Loss: 1.4219 | Val RÂ²: -0.0424
Epoch 28/100 | Train Loss: 1.3679 | Val Loss: 1.4230 | Val RÂ²: -0.0476
Epoch 29/100 | Train Loss: 1.3662 | Val Loss: 1.4234 | Val RÂ²: -0.0315
  ðŸŽ¯ New best model saved with RÂ²: -0.0315
Epoch 30/100 | Train Loss: 1.3650 | Val Loss: 1.4216 | Val RÂ²: -0.0436
Epoch 31/100 | Train Loss: 1.3630 | Val Loss: 1.4256 | Val RÂ²: -0.0670
Epoch 32/100 | Train Loss: 1.3609 | Val Loss: 1.4226 | Val RÂ²: -0.0587
Epoch 33/100 | Train Loss: 1.3602 | Val Loss: 1.4290 | Val RÂ²: -0.0523
Epoch 34/100 | Train Loss: 1.3585 | Val Loss: 1.4339 | Val RÂ²: -0.0473
Epoch 35/100 | Train Loss: 1.3563 | Val Loss: 1.4238 | Val RÂ²: -0.0415
Epoch 36/100 | Train Loss: 1.3579 | Val Loss: 1.4214 | Val RÂ²: -0.0432
Epoch 37/100 | Train Loss: 1.3549 | Val Loss: 1.4223 | Val RÂ²: -0.0348
Epoch 38/100 | Train Loss: 1.3535 | Val Loss: 1.4212 | Val RÂ²: -0.0343
Epoch 39/100 | Train Loss: 1.3536 | Val Loss: 1.4207 | Val RÂ²: -0.0366
Epoch 40/100 | Train Loss: 1.3515 | Val Loss: 1.4199 | Val RÂ²: -0.0386
Epoch 41/100 | Train Loss: 1.3506 | Val Loss: 1.4227 | Val RÂ²: -0.0305
  ðŸŽ¯ New best model saved with RÂ²: -0.0305
Epoch 42/100 | Train Loss: 1.3489 | Val Loss: 1.4236 | Val RÂ²: -0.0234
  ðŸŽ¯ New best model saved with RÂ²: -0.0234
Epoch 43/100 | Train Loss: 1.3485 | Val Loss: 1.4214 | Val RÂ²: -0.0259
Epoch 44/100 | Train Loss: 1.3474 | Val Loss: 1.4220 | Val RÂ²: -0.0277
Epoch 45/100 | Train Loss: 1.3463 | Val Loss: 1.4206 | Val RÂ²: -0.0246
Epoch 46/100 | Train Loss: 1.3458 | Val Loss: 1.4215 | Val RÂ²: -0.0229
  ðŸŽ¯ New best model saved with RÂ²: -0.0229
Epoch 47/100 | Train Loss: 1.3403 | Val Loss: 1.4223 | Val RÂ²: -0.0202
  ðŸŽ¯ New best model saved with RÂ²: -0.0202
Epoch 48/100 | Train Loss: 1.3382 | Val Loss: 1.4198 | Val RÂ²: -0.0326
Epoch 49/100 | Train Loss: 1.3361 | Val Loss: 1.4229 | Val RÂ²: -0.0163
  ðŸŽ¯ New best model saved with RÂ²: -0.0163
Epoch 50/100 | Train Loss: 1.3353 | Val Loss: 1.4214 | Val RÂ²: -0.0249
Epoch 51/100 | Train Loss: 1.3353 | Val Loss: 1.4218 | Val RÂ²: -0.0243
Epoch 52/100 | Train Loss: 1.3342 | Val Loss: 1.4210 | Val RÂ²: -0.0232
Epoch 53/100 | Train Loss: 1.3307 | Val Loss: 1.4217 | Val RÂ²: -0.0168
Epoch 54/100 | Train Loss: 1.3294 | Val Loss: 1.4213 | Val RÂ²: -0.0168
Epoch 55/100 | Train Loss: 1.3290 | Val Loss: 1.4208 | Val RÂ²: -0.0172
Epoch 56/100 | Train Loss: 1.3283 | Val Loss: 1.4211 | Val RÂ²: -0.0151
  ðŸŽ¯ New best model saved with RÂ²: -0.0151
Epoch 57/100 | Train Loss: 1.3274 | Val Loss: 1.4212 | Val RÂ²: -0.0174
Epoch 58/100 | Train Loss: 1.3267 | Val Loss: 1.4229 | Val RÂ²: -0.0131
  ðŸŽ¯ New best model saved with RÂ²: -0.0131
Epoch 59/100 | Train Loss: 1.3255 | Val Loss: 1.4212 | Val RÂ²: -0.0153
Epoch 60/100 | Train Loss: 1.3251 | Val Loss: 1.4227 | Val RÂ²: -0.0141
Epoch 61/100 | Train Loss: 1.3244 | Val Loss: 1.4212 | Val RÂ²: -0.0153
Epoch 62/100 | Train Loss: 1.3254 | Val Loss: 1.4216 | Val RÂ²: -0.0155
Epoch 63/100 | Train Loss: 1.3244 | Val Loss: 1.4226 | Val RÂ²: -0.0144
Epoch 64/100 | Train Loss: 1.3237 | Val Loss: 1.4235 | Val RÂ²: -0.0139
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/local/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/workspace/src/train.py", line 154, in <module>
    main()
  File "/workspace/src/train.py", line 117, in main
    train_loss = train_epoch(model, train_loader, criterion, optimizer, epoch)
  File "/workspace/src/train.py", line 23, in train_epoch
    for batch_idx, (title_emb, num, dom_ids, usr_ids, y) in enumerate(train_loader):
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 789, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 211, in collate
    return [
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 212, in <listcomp>
    collate(samples, collate_fn_map=collate_fn_map)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 155, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 272, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
KeyboardInterrupt
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/local/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/workspace/src/train.py", line 154, in <module>
    main()
  File "/workspace/src/train.py", line 117, in main
    train_loss = train_epoch(model, train_loader, criterion, optimizer, epoch)
  File "/workspace/src/train.py", line 23, in train_epoch
    for batch_idx, (title_emb, num, dom_ids, usr_ids, y) in enumerate(train_loader):
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 733, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 789, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 211, in collate
    return [
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 212, in <listcomp>
    collate(samples, collate_fn_map=collate_fn_map)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 155, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
  File "/usr/local/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py", line 272, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
KeyboardInterrupt
